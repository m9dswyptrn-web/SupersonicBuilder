=== Auto-Tune .env ===
→ Backend: cuda
→ Quant:   Q4_K_M
→ Context: 4096
→ Threads: 8
→ Best matching model: llama-3.1-8b-q4_k_m.gguf
✅ Updated .env