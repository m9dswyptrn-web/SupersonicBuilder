import os
import json
import platform
import socket
import subprocess
from datetime import datetime, timezone
from pathlib import Path
from flask import Flask, request, render_template_string, jsonify, Response
from dotenv import load_dotenv
load_dotenv()

import sys, time, re
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))
from desktop.webui.agent_loader import load_agent

PORT = int(os.getenv("PORT", "7860"))
agent = load_agent()

CACHE_DIR = Path(".supersonic_cache")
CACHE_DIR.mkdir(exist_ok=True)
BENCH_JSON = CACHE_DIR / "bench.json"
BENCH_ONCE = CACHE_DIR / "bench_once.json"

# ---------- tiny utils ----------
def read_env_var(key, default=""):
    val = os.getenv(key)
    if val is not None:
        return val
    envp = Path(".env")
    if envp.exists():
        for line in envp.read_text(encoding="utf-8").splitlines():
            if "=" in line and not line.strip().startswith("#"):
                k, v = line.split(":", 1) if ":" in line and "=" not in line else line.split("=", 1)
                if k.strip() == key:
                    return v.strip()
    return default

def detect_status():
    """
    Returns:
      {"status":"ok|cpu|missing|error", "backend":"cuda|rocm|metal|cpu|unknown",
       "model":"name", "details":"..."}
    """
    model_path = read_env_var("AGENT_MODEL", "gguf/llama-3.1-8b-q4_0.gguf")
    backend = "unknown"
    details = ""
    try:
        out = subprocess.check_output([sys.executable, "scripts/gpu_detect.py"], text=True, timeout=6)
        for line in out.splitlines():
            if line.startswith("Backend:"):
                backend = line.split(":", 1)[1].strip()
                break
    except Exception as e:
        details = f"gpu_detect error: {e}"

    model_exists = Path(model_path).exists()
    if not model_exists:
        return {"status": "missing", "backend": backend, "model": Path(model_path).name, "details": "Model file not found"}

    if backend in ("cuda", "rocm", "metal"):
        return {"status": "ok", "backend": backend, "model": Path(model_path).name, "details": details or "accelerated"}
    if backend in ("cpu", "unknown"):
        return {"status": "cpu", "backend": backend, "model": Path(model_path).name, "details": details or "CPU mode"}
    return {"status": "error", "backend": backend, "model": Path(model_path).name, "details": details or "unknown"}

def play_ping(ok: bool, msg: str = ""):
    script = Path("scripts/post_tune_ping.py")
    if not script.exists():
        return {"played": False, "reason": "post_tune_ping.py not found"}
    try:
        if ok:
            subprocess.run([sys.executable, str(script)], check=False)
        else:
            subprocess.run([sys.executable, str(script), "--error", msg or "Triggered error ping"], check=False)
        return {"played": True}
    except Exception as e:
        return {"played": False, "reason": str(e)}

def speak_status_message():
    stat = detect_status()
    ctx = read_env_var("LLM_CTX", "n/a")
    th  = read_env_var("LLM_THREADS", "n/a")
    msg = (
        f"Supersonic status {stat['status']}. "
        f"Backend {stat['backend']}. "
        f"Model {stat['model']}. "
        f"Context {ctx}. Threads {th}."
    )
    script = Path("scripts/post_tune_ping.py")
    if not script.exists():
        return {"spoken": False, "reason": "post_tune_ping.py not found"}
    try:
        subprocess.run([sys.executable, str(script), "--say", msg], check=False)
        return {"spoken": True, "message": msg}
    except Exception as e:
        return {"spoken": False, "reason": str(e)}

def read_bench_cache():
    if BENCH_JSON.exists():
        try:
            return json.loads(BENCH_JSON.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}

def save_bench_cache(data: dict):
    try:
        BENCH_JSON.write_text(json.dumps(data, indent=2), encoding="utf-8")
    except Exception:
        pass

def run_bench():
    script = Path("scripts/bench_llm.py")
    if not script.exists():
        return {"ok": False, "error": "bench_llm.py not found"}
    try:
        out = subprocess.check_output([sys.executable, str(script)], text=True, timeout=120)
    except subprocess.TimeoutExpired:
        return {"ok": False, "error": "benchmark timeout"}
    except Exception as e:
        return {"ok": False, "error": str(e)}

    runs = []
    for line in out.splitlines():
        m = re.search(r"Run\s+(\d+):\s*~(\d+)\s+tokens.*?‚Üí\s*([\d\.]+)\s+tok/s", line)
        if m:
            runs.append({"run": int(m.group(1)), "gen_tokens": int(m.group(2)), "toks_per_sec": float(m.group(3))})
    avg = None
    m2 = re.search(r"Avg:\s*~(\d+)\s+tokens.*?([\d\.]+)\s+tok/s", out)
    if m2:
        avg = {"avg_tokens_per_run": int(m2.group(1)), "avg_tok_per_sec": float(m2.group(2))}
    res = {"ok": True, "runs": runs, "avg": avg, "raw": out, "ts": int(time.time())}
    save_bench_cache(res)
    return res

def reset_bench_cache():
    deleted = []
    for p in (BENCH_JSON, BENCH_ONCE):
        try:
            if p.exists():
                p.unlink()
                deleted.append(p.name)
        except Exception:
            pass
    return deleted

def git_commit_short():
    try:
        out = subprocess.check_output(["git", "rev-parse", "--short", "HEAD"], text=True, stderr=subprocess.DEVNULL, timeout=3)
        return out.strip()
    except Exception:
        return None

def make_export_payload():
    bench = read_bench_cache()
    if not bench or not isinstance(bench, dict):
        bench = run_bench()
    stat = detect_status()
    meta = {
        "hostname": socket.gethostname(),
        "os": f"{platform.system()} {platform.release()} {platform.machine()}",
        "python": platform.python_version(),
        "backend": stat.get("backend", "unknown"),
        "model": stat.get("model", "n/a"),
        "commit": git_commit_short() or "n/a",
        "utc": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    }
    return {"meta": meta, "benchmark": bench}

def make_env_summary():
    keys = ["AGENT_MODEL", "LLM_CTX", "LLM_THREADS", "DOCS_DIR", "PORT"]
    data = {k: read_env_var(k, "") for k in keys}
    try:
        if data.get("AGENT_MODEL"):
            data["AGENT_MODEL_NAME"] = Path(data["AGENT_MODEL"]).name
    except Exception:
        pass
    stat = detect_status()
    data["BACKEND"] = stat.get("backend", "unknown")
    data["MODEL_PRESENT"] = "yes" if stat.get("status") in ("ok", "cpu") else "no"
    return data

# ---------- HTML ----------
TPL = '''
<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Supersonic Local</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin:20px; }
    .bar { display:flex; align-items:center; gap:12px; margin-bottom:14px; flex-wrap:wrap; }
    .led { width:12px; height:12px; border-radius:50%; box-shadow:0 0 6px rgba(0,0,0,.25); }
    .led.ok { background:#10b981; }      /* green */
    .led.cpu { background:#f59e0b; }     /* amber */
    .led.missing, .led.error { background:#ef4444; } /* red */
    .led.ready-ok { background:#10b981; }
    .led.ready-no { background:#ef4444; }
    .tag { padding:2px 8px; border-radius:999px; font-size:12px; background:#111; color:#fff; }
    .muted { color:#888; font-size:12px; }
    .row { display:flex; gap:10px; align-items:center; flex-wrap:wrap; }
    input[name="q"] { width:70%; padding:8px; font-size:14px; }
    button, a.pill { padding:8px 12px; font-size:14px; }
    pre { background:#0b0b0b; color:#e5e7eb; padding:12px; border-radius:8px; white-space:pre-wrap; }
    .pill { border:1px solid #333; background:#171717; color:#e5e7eb; text-decoration:none; display:inline-block; border-radius:8px; cursor:pointer; }
    .card { border:1px solid #2a2a2a; background:#0f0f10; color:#eee; border-radius:10px; padding:12px; margin-top:14px; }
    .card h3 { margin:0 0 8px 0; font-size:16px; }
    .kv { display:flex; gap:12px; flex-wrap:wrap; font-size:13px; color:#bbb; }
    .kv span { background:#151515; padding:2px 8px; border-radius:6px; }
    .links { display:flex; gap:8px; flex-wrap:wrap; margin-top:8px; }
    .help { border:1px solid #333; background:#111; color:#fff; border-radius:12px; padding:0 8px; line-height:22px; height:22px; cursor:pointer; }
    .toast { position:fixed; right:16px; bottom:16px; background:#111; color:#fff; border:1px solid #333; border-radius:8px; padding:10px 12px; opacity:0; transform:translateY(8px); transition:all .2s ease; }
    .toast.show { opacity:1; transform:translateY(0); }
    /* modal */
    .modal { position:fixed; inset:0; background:rgba(0,0,0,.55); display:none; align-items:center; justify-content:center; z-index:9999; }
    .modal.show { display:flex; }
    .modal-content { width:min(780px,92vw); background:#0f0f10; color:#eee; border:1px solid #2a2a2a; border-radius:12px; padding:16px; box-shadow:0 10px 30px rgba(0,0,0,.5); }
    .modal-content h3 { margin:0 0 8px 0; }
    .modal-content pre { background:#0b0b0b; max-height:40vh; overflow:auto; }
    .modal-actions { display:flex; gap:8px; justify-content:flex-end; margin-top:10px; }
  </style>
</head>
<body>
  <div class="bar">
    <!-- STATUS LED -->
    <div id="led" class="led cpu" title="Status LED"></div>
    <div id="statusText" class="muted" title="Gathering status‚Ä¶">Status: checking‚Ä¶</div>
    <span id="backend" class="tag" title="backend engine">backend: ‚Ä¶</span>
    <span id="model" class="tag" title="model file">model: ‚Ä¶</span>
    <button class="help" onclick="openStatusHelp()">?</button>

    <!-- READY LED -->
    <div id="ledReady" class="led ready-no" title="Readiness LED" style="margin-left:16px;"></div>
    <div id="readyText" class="muted" title="Evaluating readiness‚Ä¶">Ready: checking‚Ä¶</div>
    <button class="help" onclick="openReadyHelp()">?</button>

    <button class="pill" onclick="pingSound(true)"  title="Play success chime">Test ‚úÖ</button>
    <button class="pill" onclick="pingSound(false)" title="Play error chime">Test ‚ùå</button>
    <button class="pill" onclick="speakStatus()" title="Speak current status">Speak üó£Ô∏è</button>
  </div>

  <div class="row">
    <form method="post" action="/ask">
      <input name="q" placeholder="Ask the agent‚Ä¶"/>
      <button class="pill">Ask</button>
    </form>
    <form action="/api/ingest" method="post" style="margin-left:4px;">
      <button class="pill" title="Ingest docs from DOCS_DIR">Ingest Docs</button>
    </form>
  </div>

  <div class="card" id="benchCard">
    <h3>Performance</h3>
    <div class="kv">
      <span id="benchAvg">avg: ‚Ä¶ tok/s</span>
      <span id="benchTokens">tokens/run: ‚Ä¶</span>
      <span id="benchWhen">updated: ‚Ä¶</span>
    </div>
    <div class="links">
      <button class="pill" onclick="runBench()">Run Bench</button>
      <button class="pill" onclick="resetBench()">Reset & Re-Bench</button>
      <button class="pill" onclick="pingAll()">Ping All üöÄ</button>
      <a class="pill" href="/api/bench/export" title="Download latest bench JSON" target="_blank">Download Bench JSON ‚¨áÔ∏è</a>
    </div>
  </div>

  <div class="card" id="apiQuick">
    <h3>API Quick Actions (copy curl)</h3>
    <div style="display:flex; flex-wrap:wrap; gap:8px;">
      <button class="pill" onclick="copyCurl('bench')">curl POST /api/bench</button>
      <button class="pill" onclick="copyCurl('reset')">curl POST /api/bench/reset</button>
      <button class="pill" onclick="copyCurl('ok')">curl POST /api/status/sound?ok=1</button>
      <button class="pill" onclick="copyCurl('err')">curl POST /api/status/sound?ok=0&msg=Model%20missing</button>
      <button class="pill" onclick="copyCurl('speak')">curl POST /api/status/speak</button>
      <button class="pill" onclick="copyCurl('export')">curl GET /api/bench/export</button>
      <button class="pill" onclick="copyCurl('pingall')">curl POST /api/pingall</button>
    </div>
    <div class="links">
      <a class="pill" href="/api/status" target="_blank">Open /api/status</a>
      <a class="pill" href="/api/readyz" target="_blank">Open /api/readyz</a>
      <a class="pill" href="/api/bench" target="_blank">Open /api/bench (GET)</a>
      <a class="pill" href="/api/bench/export" target="_blank">Open /api/bench/export</a>
    </div>
  </div>

  <div class="card" id="envCard">
    <h3>Environment</h3>
    <div class="kv" id="envKv"></div>
    <div class="links">
      <button class="pill" onclick="copyEnv()">Copy .env summary</button>
      <a class="pill" href="/api/env/summary" target="_blank">View .env summary</a>
    </div>
  </div>

  <pre id="resp">{{ resp }}</pre>

  <!-- Modal -->
  <div id="modal" class="modal" onclick="modalBgClose(event)">
    <div class="modal-content">
      <h3 id="modalTitle">Help</h3>
      <div id="modalBody" style="font-size:14px; line-height:1.45;"></div>
      <pre id="modalJson"></pre>
      <div class="modal-actions">
        <button class="pill" onclick="copyModal()">Copy details</button>
        <button class="pill" onclick="closeModal()">Close</button>
      </div>
    </div>
  </div>

  <div id="toast" class="toast">Copied!</div>

<script>
function tsToLocal(ts){
  if(!ts) return 'n/a';
  try{ return new Date(ts*1000).toLocaleString(); }catch(e){ return ''+ts; }
}

let _lastStatus = null;
let _lastReady  = null;

async function refreshStatus(){
  try{
    const r = await fetch('/api/status');
    const j = await r.json();
    _lastStatus = j;
    const led = document.getElementById('led');
    const st  = document.getElementById('statusText');
    const be  = document.getElementById('backend');
    const md  = document.getElementById('model');

    const details = (j.details || '').trim();
    led.className = 'led ' + j.status;

    const statusTip = [
      `status=${j.status}`,
      j.backend ? `backend=${j.backend}` : null,
      j.model   ? `model=${j.model}`     : null,
      details   ? `details=${details}`   : null
    ].filter(Boolean).join(' ¬∑ ');

    led.title = statusTip || 'Status LED';
    st.title  = statusTip || 'Status';
    be.title  = `backend=${j.backend || 'unknown'}`;
    md.title  = `model=${j.model || 'n/a'}`;

    st.textContent = `Status: ${j.status}${details ? ' ‚Äî ' + details : ''}`;
    be.textContent = `backend: ${j.backend || 'unknown'}`;
    md.textContent = `model: ${j.model || 'n/a'}`;
  }catch(e){
    const led = document.getElementById('led');
    const st  = document.getElementById('statusText');
    led.className = 'led error';
    led.title = 'Status: unreachable';
    st.textContent = 'Status: error ‚Äî cannot reach /api/status';
    st.title = 'Cannot reach /api/status';
  }
}

async function refreshReady(){
  try{
    const r = await fetch('/api/readyz');
    const j = await r.json();
    _lastReady = j;
    const ledR = document.getElementById('ledReady');
    const rt  = document.getElementById('readyText');

    ledR.className = 'led ' + (j.ok ? 'ready-ok' : 'ready-no');

    const parts = [
      `ok=${j.ok ? 'true' : 'false'}`,
      j.backend         ? `backend=${j.backend}` : null,
      `model_ready=${j.model_ready ? 'true' : 'false'}`,
      `backend_known=${j.backend_known ? 'true' : 'false'}`
    ];
    if (j.require_recent_bench !== undefined) {
      parts.push(`require_recent_bench=${j.require_recent_bench ? 'true' : 'false'}`);
      if (j.require_recent_bench) {
        parts.push(`bench_ok=${j.bench_ok ? 'true' : 'false'}`);
        if (j.bench_age_sec !== null && j.bench_age_sec !== undefined) {
          parts.push(`bench_age_sec=${j.bench_age_sec}`);
        }
        parts.push(`bench_fresh_sec=${j.bench_fresh_sec}`);
      }
    }
    const tip = parts.filter(Boolean).join(' ¬∑ ');
    ledR.title = tip || 'Readiness LED';
    const extra = (j.require_recent_bench && !j.bench_ok) ? ' (bench stale)' : '';
    rt.textContent = `Ready: ${j.ok ? 'yes' : 'no'}${j.backend ? ' backend=' + j.backend : ''}${extra}`;
    rt.title = tip || 'Readiness details';
  }catch(e){
    const ledR = document.getElementById('ledReady');
    const rt  = document.getElementById('readyText');
    ledR.className = 'led ready-no';
    ledR.title = 'Readiness: unreachable';
    rt.textContent = 'Ready: error ‚Äî cannot reach /api/readyz';
    rt.title = 'Cannot reach /api/readyz';
  }
}

async function loadBench(){
  try{
    const r = await fetch('/api/bench', {method:'GET'});
    const j = await r.json();
    const a = document.getElementById('benchAvg');
    const t = document.getElementById('benchTokens');
    const w = document.getElementById('benchWhen');

    if(j.ok && j.avg){
      a.textContent = `avg: ${j.avg.avg_tok_per_sec.toFixed(1)} tok/s`;
      t.textContent = `tokens/run: ${j.avg.avg_tokens_per_run}`;
      w.textContent = `updated: ${tsToLocal(j.ts)}`;
    }else if(j.ok){
      a.textContent = `avg: n/a`;
      t.textContent = `tokens/run: n/a`;
      w.textContent = `updated: ${tsToLocal(j.ts)}`;
    }else{
      a.textContent = `avg: n/a`;
      t.textContent = `tokens/run: n/a`;
      w.textContent = `updated: error`;
    }
  }catch(e){
    console.warn('bench load error', e);
  }
}

async function runBench(){
  try{
    await fetch('/api/bench', {method:'POST'});
    await loadBench();
    await refreshReady();
  }catch(e){
    console.warn('bench error', e);
  }
}

async function resetBench(){
  try{
    await fetch('/api/bench/reset', {method:'POST'});
    await loadBench();
    await refreshReady();
  }catch(e){
    console.warn('bench reset error', e);
  }
}

async function pingAll(){
  try{
    const r = await fetch('/api/pingall', {method:'POST'});
    const j = await r.json();
    await loadBench();
    await refreshReady();
    showToast(j.ok ? 'Ping All OK' : ('Ping All: ' + (j.reason || 'error')));
  }catch(e){
    console.warn('pingall error', e);
    showToast('Ping All error');
  }
}

function showToast(text){
  const t = document.getElementById('toast');
  t.textContent = text || 'Copied!';
  t.classList.add('show');
  setTimeout(()=> t.classList.remove('show'), 1400);
}

async function copyCurl(kind){
  const base = window.location.origin;
  let cmd = '';
  switch(kind){
    case 'bench':   cmd = `curl -X POST "${base}/api/bench"`; break;
    case 'reset':   cmd = `curl -X POST "${base}/api/bench/reset"`; break;
    case 'ok':      cmd = `curl -X POST "${base}/api/status/sound?ok=1"`; break;
    case 'err':     cmd = `curl -X POST "${base}/api/status/sound?ok=0&msg=Model%20missing"`; break;
    case 'speak':   cmd = `curl -X POST "${base}/api/status/speak"`; break;
    case 'export':  cmd = `curl "${base}/api/bench/export" -o bench_export.json`; break;
    case 'pingall': cmd = `curl -X POST "${base}/api/pingall"`; break;
    default:        cmd = '# unknown'; break;
  }
  try{
    await navigator.clipboard.writeText(cmd);
    showToast('Copied curl ‚Üí clipboard');
  }catch(e){
    const ta = document.createElement('textarea');
    ta.value = cmd;
    document.body.appendChild(ta);
    ta.select();
    document.execCommand('copy');
    document.body.removeChild(ta);
    showToast('Copied (fallback)');
  }
}

async function copyEnv(){
  try{
    const r = await fetch('/api/env/summary');
    const j = await r.json();
    const text = JSON.stringify(j, null, 2);
    await navigator.clipboard.writeText(text);
    showToast('.env summary copied');
  }catch(e){
    console.warn('env copy error', e);
  }
}

/* ---------- Help modal plumbing ---------- */
function openModal(title, bodyHtml, jsonObj){
  const m = document.getElementById('modal');
  document.getElementById('modalTitle').textContent = title || 'Help';
  document.getElementById('modalBody').innerHTML = bodyHtml || '';
  const pj = document.getElementById('modalJson');
  pj.textContent = jsonObj ? JSON.stringify(jsonObj, null, 2) : '';
  m.classList.add('show');
}
function closeModal(){ document.getElementById('modal').classList.remove('show'); }
function modalBgClose(ev){ if(ev.target.id === 'modal'){ closeModal(); } }
document.addEventListener('keydown', (e)=>{ if(e.key === 'Escape'){ closeModal(); }});
async function copyModal(){
  const pj = document.getElementById('modalJson').textContent || '';
  try{
    await navigator.clipboard.writeText(pj);
    showToast('Details copied');
  }catch(e){ showToast('Copy failed'); }
}

function openStatusHelp(){
  const j = _lastStatus || {};
  const fixes = [
    '<b>missing</b>: Place the model file at <code>$AGENT_MODEL</code> or set AGENT_MODEL in <code>.env</code> to an existing path.',
    '<b>cpu</b>: GPU not detected. If you expect GPU, check drivers (CUDA/ROCm/Metal), then re-run <code>scripts/gpu_detect.py</code>.',
    '<b>error/unknown</b>: See <i>details</i>. Often a permission/path issue.'
  ].join('<br>');
  const body = `
    <p><b>Status LED</b> reflects <code>/api/status</code>.</p>
    <ul>
      <li><b>status</b>: ok | cpu | missing | error</li>
      <li><b>backend</b>: cuda | rocm | metal | cpu | unknown</li>
      <li><b>model</b>: model filename</li>
      <li><b>details</b>: extra info from detector</li>
    </ul>
    <p><b>Fixes</b><br>${fixes}</p>
  `;
  openModal('Status LED Help', body, j);
}

function openReadyHelp(){
  const j = _lastReady || {};
  const body = `
    <p><b>Ready LED</b> reflects <code>/api/readyz</code>.</p>
    <ul>
      <li><b>ok</b>: all readiness checks passed</li>
      <li><b>model_ready</b>: model present (status ok|cpu)</li>
      <li><b>backend_known</b>: backend recognized (cuda|rocm|metal|cpu)</li>
      <li><b>require_recent_bench</b>: if true, bench must be fresh</li>
      <li><b>bench_ok</b>: bench within freshness window</li>
      <li><b>bench_age_sec</b> vs <b>bench_fresh_sec</b></li>
    </ul>
    <p><b>Common fixes</b></p>
    <ol>
      <li>If <code>model_ready=false</code>: set <code>AGENT_MODEL</code> in <code>.env</code> or place the .gguf file.</li>
      <li>If <code>backend_known=false</code>: install/enable GPU runtime (CUDA/ROCm/Metal) or continue in CPU.</li>
      <li>If bench is stale and required: click <b>Run Bench</b> or disable freshness via <code>REQUIRE_RECENT_BENCH=0</code>.</li>
    </ol>
  `;
  openModal('Ready LED Help', body, j);
}

refreshStatus();
refreshReady();
setInterval(refreshStatus, 3000);
setInterval(refreshReady, 3500);
loadBench();
</script>
</body>
</html>
'''

app = Flask(__name__)

@app.route("/", methods=["GET"])
def index():
    return render_template_string(TPL, resp="")

@app.route("/ask", methods=["POST"])
def ask():
    q = request.form.get("q","").strip()
    out = agent.query(q)
    return render_template_string(TPL, resp=out)

@app.route("/api/ingest", methods=["POST"])
def ingest():
    status = "ingested"
    try:
        d = Path(os.getenv("DOCS_DIR","docs"))
        status = agent.ingest_dir(d)
    except Exception as e:
        status = f"error: {e}"
    return jsonify({"status": status})

@app.route("/api/status", methods=["GET"])
def api_status():
    return jsonify(detect_status())

@app.route("/api/status/sound", methods=["POST"])
def api_status_sound():
    ok = request.args.get("ok", "1") in ("1","true","True","yes","y")
    msg = request.args.get("msg", "")
    res = play_ping(ok, msg)
    return jsonify(res)

@app.route("/api/status/speak", methods=["POST"])
def api_status_speak():
    res = speak_status_message()
    return jsonify(res)

@app.route("/api/bench", methods=["GET","POST"])
def api_bench():
    if request.method == "GET":
        cache = read_bench_cache()
        if cache:
            return jsonify(cache | {"ok": True})
        return jsonify({"ok": True, "avg": None, "ts": None})
    res = run_bench()
    return jsonify(res)

@app.route("/api/bench/reset", methods=["POST"])
def api_bench_reset():
    deleted = reset_bench_cache()
    res = run_bench()
    return jsonify({"deleted": deleted, **res})

@app.route("/api/bench/export", methods=["GET"])
def api_bench_export():
    payload = make_export_payload()
    body = json.dumps(payload, indent=2)
    headers = {"Content-Disposition": "attachment; filename=bench_export.json"}
    return Response(body, mimetype="application/json", headers=headers)

@app.route("/api/env/summary", methods=["GET"])
def api_env_summary():
    return jsonify(make_env_summary())

@app.route("/api/pingall", methods=["POST"])
def api_ping_all():
    stat = detect_status()
    ok = stat.get("status") in ("ok", "cpu")
    reason = None
    if not ok:
        reason = f"status={stat.get('status')} details={stat.get('details','')}"
    bench = run_bench() if ok else {"ok": False, "error": "status not ready"}
    speak = speak_status_message()
    if ok:
        play_ping(True, "")
    else:
        play_ping(False, reason or "not ready")
    return jsonify({
        "ok": ok and bool(bench.get("ok")),
        "status": stat,
        "bench_ok": bench.get("ok", False),
        "avg": (bench.get("avg") or {}).get("avg_tok_per_sec"),
        "spoken": speak.get("spoken", False),
        "reason": reason
    })

# --- Health endpoints (liveness / readiness) ---
@app.route("/api/healthz", methods=["GET", "HEAD"])
@app.route("/api/livez",  methods=["GET", "HEAD"])
def api_healthz():
    return jsonify({"ok": True, "ts": int(time.time())})

@app.route("/api/readyz", methods=["GET"])
def api_readyz():
    """
    Readiness: require model present and backend known (ok/cpu/metal/cuda/rocm).
    Optionally require a recent bench result (‚â§ BENCH_FRESH_SEC) if REQUIRE_RECENT_BENCH=1.
    """
    REQUIRE_RECENT_BENCH = os.getenv("REQUIRE_RECENT_BENCH", "0") in ("1","true","True","yes","y")
    BENCH_FRESH_SEC = int(os.getenv("BENCH_FRESH_SEC", "43200"))  # 12h default

    stat = detect_status()
    backend = stat.get("backend")
    status  = stat.get("status")

    model_ready   = status in ("ok", "cpu")
    backend_known = backend in ("cuda", "rocm", "metal", "cpu")

    bench_ok = True
    bench_age = None
    if REQUIRE_RECENT_BENCH:
        cache = read_bench_cache()
        if cache and isinstance(cache, dict) and cache.get("ts"):
            bench_age = int(time.time()) - int(cache["ts"])
            bench_ok = bench_age <= BENCH_FRESH_SEC
        else:
            bench_ok = False

    ok = bool(model_ready and backend_known and bench_ok)
    return jsonify({
        "ok": ok,
        "model_ready": model_ready,
        "backend_known": backend_known,
        "backend": backend,
        "status": status,
        "require_recent_bench": REQUIRE_RECENT_BENCH,
        "bench_fresh_sec": BENCH_FRESH_SEC,
        "bench_ok": bench_ok,
        "bench_age_sec": bench_age
    })

if __name__ == "__main__":
    app.run(host="127.0.0.1", port=PORT, debug=False)