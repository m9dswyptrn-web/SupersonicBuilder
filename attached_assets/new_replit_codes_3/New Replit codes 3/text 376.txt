python scripts/run_offline_llm.py
# open http://127.0.0.1:7860

# In the UI:
#   ‚Ä¢ watch the LED + backend/model chips
#   ‚Ä¢ click Speak üó£Ô∏è to hear status
#   ‚Ä¢ click Run Bench ‚Üí the Performance card updates avg tok/s + tokens/run

# API checks:
curl http://127.0.0.1:7860/api/bench          # get last result
curl -X POST http://127.0.0.1:7860/api/bench   # run a new bench